{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "934e3b2b-ca42-4475-b9db-b4f2104afb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Core Brain is thinking...\n",
      "‚ùå An unexpected error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: key-here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# --- 1. Define the Structured Output (The Plan) using Pydantic ---\n",
    "# This ensures the LLM's output is predictable and easy to work with.\n",
    "\n",
    "class ToolCall(BaseModel):\n",
    "    \"\"\"A single tool call to be executed by a specialized agent.\"\"\"\n",
    "    tool_name: str = Field(..., description=\"The exact name of the tool to be called.\")\n",
    "    parameters: Dict[str, Any] = Field({}, description=\"The parameters to pass to the tool.\")\n",
    "    reasoning: str = Field(..., description=\"A brief explanation of why this tool was chosen.\")\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"The complete, step-by-step plan generated by the Core Brain.\"\"\"\n",
    "    thought: str = Field(..., description=\"A high-level summary of the plan and reasoning.\")\n",
    "    workflow_type: str = Field(..., description=\"Either 'sequential' or 'parallel'.\", enum=[\"sequential\", \"parallel\"])\n",
    "    steps: List[ToolCall] = Field(..., description=\"The sequence of tool calls to execute.\")\n",
    "\n",
    "\n",
    "# --- 2. Create the Core Brain Class ---\n",
    "\n",
    "class CoreBrain:\n",
    "    \"\"\"The central LLM orchestrator that creates plans.\"\"\"\n",
    "    def __init__(self):\n",
    "        # Initialize the OpenAI client. It will automatically find the API key\n",
    "        # from the environment variables.\n",
    "        self.client = OpenAI()\n",
    "        if not self.client.api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable not found.\")\n",
    "\n",
    "    def create_plan(self, scenario: str) -> Plan:\n",
    "        \"\"\"\n",
    "        Takes a natural language scenario and returns a structured plan.\n",
    "        \"\"\"\n",
    "        # This is the most important part: the system prompt.\n",
    "        # It guides the LLM on its role, capabilities, and expected output format.\n",
    "        system_prompt = f\"\"\"\n",
    "        You are the 'Planning Agent' for Synapse, an AI-powered last-mile coordinator for Grab.\n",
    "        Your primary role is to analyze a disruption scenario and generate a structured, step-by-step action plan in JSON format.\n",
    "        \n",
    "        You have access to the following tools:\n",
    "        - notify_customer(message: str, user_id: str): Informs the customer of a situation.\n",
    "        - reroute_driver(driver_id: str, new_task_id: str): Assigns a driver to a short, nearby delivery.\n",
    "        - get_nearby_merchants(cuisine_type: str, max_wait_time: int): Finds similar restaurants with shorter wait times.\n",
    "        - initiate_mediation_flow(case_id: str, user_id: str, driver_id: str): Starts a real-time resolution process.\n",
    "        \n",
    "        Based on the user's scenario, you must:\n",
    "        1.  Think through a logical plan to resolve the issue.\n",
    "        2.  Decide if the steps should be run 'sequential' or 'parallel'.\n",
    "        3.  Create a list of tool calls to execute.\n",
    "        4.  Provide reasoning for each step.\n",
    "        5.  Respond ONLY with a valid JSON object that conforms to the following schema.\n",
    "\n",
    "        JSON Schema:\n",
    "        {json.dumps(Plan.model_json_schema(), indent=2)}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            print(\"üß† Core Brain is thinking...\")\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\", # Or \"gpt-3.5-turbo\" for faster, cheaper prototyping\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"Scenario: {scenario}\"}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            response_json = json.loads(response.choices[0].message.content)\n",
    "            print(\"‚úÖ LLM generated a raw plan.\")\n",
    "\n",
    "            # --- Validate the output against our Pydantic model ---\n",
    "            validated_plan = Plan(**response_json)\n",
    "            print(\"‚úÖ Plan validated successfully.\")\n",
    "            return validated_plan\n",
    "\n",
    "        except ValidationError as e:\n",
    "            print(f\"‚ùå Validation Error: The LLM returned an invalid plan format. {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "# --- 3. Example Usage ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Instantiate the brain\n",
    "    brain = CoreBrain()\n",
    "    \n",
    "    # Define a disruption scenario based on your documentation\n",
    "    disruption_scenario = \"\"\"\n",
    "    An order was placed for user 'user_123' at 'Burger Palace'.\n",
    "    However, the get_merchant_status() tool detected a 40-minute kitchen prep time.\n",
    "    The assigned driver is 'driver_456'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a plan\n",
    "    generated_plan = brain.create_plan(disruption_scenario)\n",
    "    \n",
    "    if generated_plan:\n",
    "        print(\"\\n--- ü§ñ Generated Plan ---\")\n",
    "        print(f\"Thought: {generated_plan.thought}\")\n",
    "        print(f\"Workflow Type: {generated_plan.workflow_type}\")\n",
    "        print(\"Steps:\")\n",
    "        for i, step in enumerate(generated_plan.steps, 1):\n",
    "            print(f\"  {i}. Tool: {step.tool_name}\")\n",
    "            print(f\"     Params: {step.parameters}\")\n",
    "            print(f\"     Reasoning: {step.reasoning}\")\n",
    "        print(\"------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706cdb3-736a-458d-aa40-20776275f256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
